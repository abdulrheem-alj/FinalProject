import os
from flask import jsonify
from langdetect import detect
from langchain.prompts import PromptTemplate 
from langchain.chat_models import ChatOpenAI
from langchain.utilities import WikipediaAPIWrapper
from langchain.tools import Tool
import os
from langchain_core.messages import HumanMessage
import os
import json
import sqlite3
import pandas as pd
import wikipedia
import os
from langchain_community.utilities import SerpAPIWrapper
from serpapi import GoogleSearch
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.llms import OpenAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from PIL import Image
import torch
import faiss
import json
from transformers import CLIPModel, CLIPProcessor
import speech_recognition as sr
from langchain.chains import RetrievalQA

from langchain.tools import Tool
from langchain.agents import initialize_agent
from langchain.agents.agent_types import AgentType
from langchain.docstore.document import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
 
 
os.environ["SERPAPI_API_KEY"] = 
os.environ["huggingface_token"] = 
os.environ["OPENAI_API_KEY"] = 

LANGSMITH_TRACING=True
LANGSMITH_ENDPOINT=
LANGSMITH_API_KEY=
LANGSMITH_PROJECT=
OPENAI_API_KEY=

 
llm = ChatOpenAI(model="gpt-4o", temperature=0, api_key=os.getenv("OPENAI_API_KEY"))
wiki = WikipediaAPIWrapper(lang="ar")  # Ø£Ùˆ "en" Ø­Ø³Ø¨ Ø§Ù„Ù„ØºØ©


google_search = SerpAPIWrapper(serpapi_api_key=os.getenv("SERPAPI_API_KEY"))

  


#----------------------------------------------------------------------


# 1. ØªØ­Ù…ÙŠÙ„ JSON ÙƒÙ‚Ø§Ø¦Ù…Ø© Ù…Ù† Ø§Ù„Ù‚ÙˆØ§Ù…ÙŠØ³

json_path = "data/landmarks_list2.json"   # ØºÙŠÙ‘Ø± Ø¥Ù„Ù‰ Ù…Ø³Ø§Ø± Ù…Ù„ÙÙƒ
if not os.path.exists(json_path):
    raise FileNotFoundError(f"Ù„Ù… Ø£Ø¬Ø¯ Ø§Ù„Ù…Ù„Ù: {json_path}")

with open(json_path, encoding="utf-8") as f:
    data = json.load(f)              # data: List[Dict]

# 2. Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª (Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø£Ø³Ø§Ø³ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†)
seen = set()
unique = []
for item in data:
    title = item.get("title")
    if title and title not in seen:
        seen.add(title)
        unique.append(item)
print(f"âœ… Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª: Ø¨Ù‚ÙŠ {len(unique)} Ø¹Ù†ØµØ±Ù‹Ø§")

# 3. ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ DataFrame
df = pd.DataFrame(unique)
df["id"] = df.index.astype(str)     # Ù…ÙØªØ§Ø­ ÙØ±ÙŠØ¯

# 4. Ø¨Ù†Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ metadata ÙÙŠ SQLite (Ø§Ø®ØªÙŠØ§Ø±ÙŠ ÙˆÙ„ÙƒÙ† Ù…ÙÙŠØ¯ Ù„Ù„Ø¨Ø­Ø« Ø§Ù„ÙˆØµÙÙŠ)
conn = sqlite3.connect("landmarks2.db")
df[["id", "title", "url"]].to_sql(
    "landmarks_meta", conn, if_exists="replace", index=False
)
conn.close()
print("âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ metadata ÙÙŠ landmarks2.db")

# 5. Ø¥Ø¹Ø¯Ø§Ø¯ Embeddings + Vector Store (FAISS)
texts     = df["description"].tolist()   # Ø£Ùˆ Ø­Ù‚Ù„ Ø¢Ø®Ø± ÙŠØ­ØªÙˆÙŠ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØ¶Ù…ÙŠÙ†Ù‡Ø§
metadatas = df[["id", "title", "url"]].to_dict(orient="records")

 
# ØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Ù…Ø³ØªÙ†Ø¯Ø§Øª LangChain
documents = [Document(page_content=item["description"]) for item in data]

# chunking
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
chunks = splitter.split_documents(documents)

# ØªÙˆÙ„ÙŠØ¯ embeddings + Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© FAISS
embedding = OpenAIEmbeddings()
vectorstore = FAISS.from_documents(chunks, embedding)

# Ø­ÙØ¸Ù‡Ø§ Ù„Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ù„Ø§Ø­Ù‚Ù‹Ø§
vectorstore.save_local("faiss_landmarks")


embeddings = OpenAIEmbeddings()      # ØªØ£ÙƒØ¯ Ù…Ù† Ø¶Ø¨Ø· OPENAI_API_KEY
vectordb   = FAISS.from_texts(texts, embeddings, metadatas=metadatas)
vectordb.save_local("faiss_landmarks")
print("âœ… ÙÙ‡Ø±Ø³ FAISS Ø¬Ø§Ù‡Ø² ÙˆÙ…Ø­ÙÙˆØ¸")

# 6. ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙ‡Ø±Ø³ ÙˆØªÙ‡ÙŠØ¦Ø© Retriever
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS

# your embeddings
embeddings = OpenAIEmbeddings()

# load the FAISS index you saved earlier, allowing your own pickle
vectordb = FAISS.load_local(
    "faiss_landmarks",
    embeddings,
    allow_dangerous_deserialization=True
)

retriever = vectordb.as_retriever(search_kwargs={"k": 3}) 

 
#----------------------------------------------------------------------
device = "cuda" if torch.cuda.is_available() else "cpu"
clip_model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32").to(device)
clip_processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

index = faiss.read_index("data/embeddings/index.faiss")
with open("data/embeddings/labels.json") as f:
    labels = json.load(f)



def detect_language(text):
    try:
        lang = detect(text)
        return "ar" if lang == "ar" else "en"
    except:
        return "en"  # fallback
    
def enhance_query_for_tourism(query: str, lang="ar"):
    if lang == "ar":
        return f"Ù…Ø¹Ù„Ù… Ø³ÙŠØ§Ø­ÙŠ {query}"
    else:
        return f"tourist attraction {query}"


def get_prompt_by_lang( lang="ar"):
    if lang == "ar":
        prompt  = PromptTemplate(
        input_variables=["context", "landmark"],
        template="""Ø£Ù†Øª Ù…Ø±Ø´Ø¯ Ø³ÙŠØ§Ø­ÙŠ Ø°ÙƒÙŠ ÙˆØ®Ø¨ÙŠØ±.

        Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©ØŒ Ø£Ù†Ø´Ø¦ ÙÙ‚Ø±Ø© Ø¬Ø°Ø§Ø¨Ø© ÙˆÙ…ÙÙŠØ¯Ø© Ù„Ù„Ø³Ø§Ø¦Ø­ Ø¹Ù† Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø³ÙŠØ§Ø­ÙŠ "{landmark}" ØªØªØ¶Ù…Ù† Ù…Ø§ ÙŠÙ„ÙŠ:
 (Ù…Ø¹ ØªØ¶Ù…ÙŠÙ† Ø³ØªØ§ÙŠÙ„ ÙƒÙˆØ¯ html Ø¨Ø¯ÙˆÙ† Ø±ÙˆØ§Ø¨Ø· ÙˆØ£Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© )
        1. ÙˆØµÙ Ù…Ù…ÙŠØ² Ù„Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø³ÙŠØ§Ø­ÙŠ ÙˆØªØ§Ø±ÙŠØ®Ù‡ ÙˆÙ…ÙˆÙ‚Ø¹Ù‡ ÙˆØ£Ù‡Ù…ÙŠØªÙ‡.
        2. ÙˆØ³Ø§Ø¦Ù„ Ø§Ù„Ù…ÙˆØ§ØµÙ„Ø§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„ÙˆØµÙˆÙ„ Ø¥Ù„ÙŠÙ‡ (Ù…Ø«Ù„ Ø§Ù„Ù…ØªØ±ÙˆØŒ Ø£ÙˆØ¨Ø±ØŒ ÙƒØ±ÙŠÙ…ØŒ Ø£Ùˆ Ø³ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø£Ø¬Ø±Ø©).
        3. ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ù…Ø­Ù„ÙŠØ© Ù…ÙÙŠØ¯Ø© Ù„Ù„Ø³ÙŠØ§Ø­ ÙÙŠ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© (Ù…Ø«Ù„ Ø§Ù„Ø®Ø±Ø§Ø¦Ø· Ø£Ùˆ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø£Ùˆ Ø§Ù„Ù…ÙˆØ§ØµÙ„Ø§Øª).
        4. Ø§Ù‚ØªØ±Ø§Ø­ Ù…Ù‚Ø·Ø¹ Ø£Ùˆ Ù…Ù‚Ø·Ø¹ÙŠÙ† Ù…Ù† ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ù…Ø´Ù‡ÙˆØ±Ø© Ø¹Ù„Ù‰ ÙŠÙˆØªÙŠÙˆØ¨ ØªØªØ­Ø¯Ø« Ø¹Ù† Ø§Ù„Ù…Ø¹Ù„Ù… Ø£Ùˆ Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©.
        5. Ø£Ø³Ù…Ø§Ø¡ 2 Ø¥Ù„Ù‰ 3 Ø´Ø±ÙƒØ§Øª Ø³ÙŠØ§Ø­ÙŠØ© Ù…Ø­Ù„ÙŠØ© Ù…ÙˆØ«ÙˆÙ‚Ø© ÙŠÙ…ÙƒÙ†Ù‡Ø§ ØªÙ†Ø¸ÙŠÙ… Ø²ÙŠØ§Ø±Ø© Ù„Ù„Ù…Ø¹Ù„Ù….
        6. Ø¥Ø°Ø§ ØªÙˆÙØ±ØªØŒ Ø£Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø±Ø³Ù„Ø© ÙÙŠ {context}.

        ğŸ“Œ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª:
        - Ù„Ø§ ØªØ®ØªØ±Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚.
        - Ø¥Ø°Ø§ Ù„Ù… ØªØªÙˆÙØ± Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§ÙÙŠØ©ØŒ Ø£Ø°ÙƒØ± Ø£Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø­Ø¯ÙˆØ¯Ø©.
        - Ø§Ø¬Ø¹Ù„ Ø§Ù„Ù†Øµ Ø¬Ø°Ø§Ø¨Ù‹Ø§ ÙˆØ³Ù‡Ù„ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©ØŒ ÙˆÙ…Ù†Ø§Ø³Ø¨Ù‹Ø§ Ù„Ù„Ø³ÙŠØ§Ø­.
        - Ø§ÙƒØªØ¨ Ø¨Ø£Ø³Ù„ÙˆØ¨ Ø§Ø­ØªØ±Ø§ÙÙŠ ÙˆÙ…ØªØ­Ù…Ø³.
        """
        )
        return prompt
    else: 
        prompt  = PromptTemplate(
        input_variables=["context", "landmark"],
        template="""You are a smart and experienced tour guide.

        Based on the following information, create an engaging and informative paragraph (with html tags and no links and show img)
        for tourists about the landmark "{landmark}" that includes the following:

        1. A distinctive description of the landmark, its history, location, and significance.
        2. Suitable means of transportation for reaching it (such as the metro, Uber, Careem, or taxis).
        3. Useful local apps for tourists in the area (such as maps, translation, or transportation).
        4. Suggest one or two popular YouTube videos about the landmark or city.
        5. The names of two to three reliable local tour companies that can arrange a visit to the landmark.
        6. If available, display the submitted image in {context}.
        ğŸ“Œ Instructions:
        - Don't invent information that isn't relevant to the context.
        - If there isn't enough information, state that the information is limited.
        - Make the text engaging, easy to read, and tourist-friendly.
        - Write in a professional and enthusiastic style.
        """
        )
        return prompt

def get_prompt_template_by_lang( lang="ar"):
    if lang == "ar":
        prompt  = PromptTemplate(
        input_variables=["context", "question"],
        template="""
        Ø£Ù†Øª Ù…Ø±Ø´Ø¯ Ø³ÙŠØ§Ø­ÙŠ Ø°ÙƒÙŠ. 
        Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø¯Ù‚Ø© ÙˆØ¨Ø£Ø³Ù„ÙˆØ¨ Ù…Ø®ØªØµØ±:     
         (Ù…Ø¹ ØªØ¶Ù…ÙŠÙ† Ø³ØªØ§ÙŠÙ„ ÙƒÙˆØ¯ html Ø¨Ø¯ÙˆÙ† Ø±ÙˆØ§Ø¨Ø·  )

       ğŸ“š Ø§Ù„Ø³ÙŠØ§Ù‚:  
       {context}  

        ğŸ“Œ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª:
        - Ù„Ø§ ØªØ®ØªØ±Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚.
        - Ø¥Ø°Ø§ Ù„Ù… ØªØªÙˆÙØ± Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§ÙÙŠØ©ØŒ Ø£Ø°ÙƒØ± Ø£Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø­Ø¯ÙˆØ¯Ø©.
        - Ø§Ø¬Ø¹Ù„ Ø§Ù„Ù†Øµ Ø¬Ø°Ø§Ø¨Ù‹Ø§ ÙˆØ³Ù‡Ù„ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©ØŒ ÙˆÙ…Ù†Ø§Ø³Ø¨Ù‹Ø§ Ù„Ù„Ø³ÙŠØ§Ø­.
        - Ø§ÙƒØªØ¨ Ø¨Ø£Ø³Ù„ÙˆØ¨ Ø§Ø­ØªØ±Ø§ÙÙŠ ÙˆÙ…ØªØ­Ù…Ø³.

       â“ Ø§Ù„Ø³Ø¤Ø§Ù„:
        {question}

        ğŸ§  Ø§Ù„Ø¬ÙˆØ§Ø¨:
 
        """
        )
        return prompt
    else: 
        prompt  = PromptTemplate(
        input_variables=["context", "question"],
        template="""
        You are a smart tour guide.
        Use the following information to answer the question accurately and concisely:  
        (with html tags and no links and show img if it's work)

        ğŸ“š Context:
        {context}

        ğŸ“Œ Instructions:
        - Don't invent information not found in the context.
        - If not enough information is available, state that the information is limited.
        - Make the text engaging, easy to read, and tourist-friendly.
        - Write in a professional and enthusiastic style.

        â“ Question:
        {question}

        ğŸ§  Answer:  
        """
        )
        return prompt

def get_context_by_lang( lang="ar"):
    if lang == "ar":
        context  = """
             1. ÙˆØµÙ Ù…Ù…ÙŠØ² Ù„Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø³ÙŠØ§Ø­ÙŠ ÙˆØªØ§Ø±ÙŠØ®Ù‡ ÙˆÙ…ÙˆÙ‚Ø¹Ù‡ ÙˆØ£Ù‡Ù…ÙŠØªÙ‡.
        2. ÙˆØ³Ø§Ø¦Ù„ Ø§Ù„Ù…ÙˆØ§ØµÙ„Ø§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„ÙˆØµÙˆÙ„ Ø¥Ù„ÙŠÙ‡ (Ù…Ø«Ù„ Ø§Ù„Ù…ØªØ±ÙˆØŒ Ø£ÙˆØ¨Ø±ØŒ ÙƒØ±ÙŠÙ…ØŒ Ø£Ùˆ Ø³ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø£Ø¬Ø±Ø©).
        3. ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ù…Ø­Ù„ÙŠØ© Ù…ÙÙŠØ¯Ø© Ù„Ù„Ø³ÙŠØ§Ø­ ÙÙŠ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© (Ù…Ø«Ù„ Ø§Ù„Ø®Ø±Ø§Ø¦Ø· Ø£Ùˆ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø£Ùˆ Ø§Ù„Ù…ÙˆØ§ØµÙ„Ø§Øª).
        4. Ø§Ù‚ØªØ±Ø§Ø­ Ù…Ù‚Ø·Ø¹ Ø£Ùˆ Ù…Ù‚Ø·Ø¹ÙŠÙ† Ù…Ù† ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ù…Ø´Ù‡ÙˆØ±Ø© Ø¹Ù„Ù‰ ÙŠÙˆØªÙŠÙˆØ¨ ØªØªØ­Ø¯Ø« Ø¹Ù† Ø§Ù„Ù…Ø¹Ù„Ù… Ø£Ùˆ Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©.
        5. Ø£Ø³Ù…Ø§Ø¡ 2 Ø¥Ù„Ù‰ 3 Ø´Ø±ÙƒØ§Øª Ø³ÙŠØ§Ø­ÙŠØ© Ù…Ø­Ù„ÙŠØ© Ù…ÙˆØ«ÙˆÙ‚Ø© ÙŠÙ…ÙƒÙ†Ù‡Ø§ ØªÙ†Ø¸ÙŠÙ… Ø²ÙŠØ§Ø±Ø© Ù„Ù„Ù…Ø¹Ù„Ù….
        """
        return context
    else: 
        context="""
       
        1. A distinctive description of the landmark, its history, location, and significance.
        2. Suitable means of transportation for reaching it (such as the metro, Uber, Careem, or taxis).
        3. Useful local apps for tourists in the area (such as maps, translation, or transportation).
        4. Suggest one or two popular YouTube videos about the landmark or city.
        5. The names of two to three reliable local tour companies that can arrange a visit to the landmark.
        """
        
        return context

        # 6. If available, display the submitted image in {context}.

 
def search_tourist_images_on_google(landmark_name):
    params = {
        "engine": "google",
        "q": f"{landmark_name}  ",
        "tbm": "isch",   
        "api_key": os.getenv("SERPAPI_API_KEY")  
    }
 
    search = GoogleSearch(params)
    results = search.get_dict()
    images = results.get("images_results", [])
    return [img["original"] for img in images[:5]] 


def smart_search(query: str, sentences=5,  lang="ar"):
    
    try: 
        wikipedia.set_lang(lang)
        results = wikipedia.search(query)
        if results:
            title = results[0]
            page = wikipedia.page(title, auto_suggest=False)
            summary = wikipedia.summary(title, sentences=sentences)


            # images = search_tourist_images_on_google(query)
            image_url = next((img for img in page.images if img.lower().endswith(('.jpg', '.png'))), None)
 
            if "wikimedia"  not in image_url:
                image_url = None
 
            return summary + (f"\n\nğŸ–¼ï¸ ØµÙˆØ±Ø©: {image_url}" if image_url else ""), image_url
    except:
        pass
 

    # 3ï¸âƒ£ Ø£Ø®ÙŠØ±Ù‹Ø§: Ø¨Ø­Ø« Ø¬ÙˆØ¬Ù„ (SerpAPI)
    try:
        serp_result = google_search.run(query)
        return f"ğŸ“ ØªÙ… Ø¬Ù„Ø¨ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ù† Google:\n\n{serp_result}", ""
    except:
        return "âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§ÙÙŠØ© Ø­ØªÙ‰ Ù…Ù† Google.", ""


def extract_landmark_name_from_text(user_input):
    system_prompt = (
        "Extract the name of the tourist attraction from the user's question. "
        "Just return the name and the name of city if found only, with no extra words."
    )
    response = llm.invoke([
        HumanMessage(content=[
            {"type": "text", "text": system_prompt},
            {"type": "text", "text": user_input}
        ])
    ])
    return response.content.strip()
 
# Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
# Smart Agent => Reg in 
def text_tool_func(query: str) -> str: 
    prompt  = get_prompt_by_lang(detect_language(query))
 
    query = enhance_query_for_tourism(query , detect_language(query))

    landmark = extract_landmark_name_from_text(query)
    context, image_url =  smart_search (landmark , 5 , detect_language(landmark))
    
    if "âŒ" in context:
        return f"ğŸ“ {landmark}\n{context}"
    
    # Ø£Ø¶Ù Ø§Ù„ØµÙˆØ±Ø© ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©
    full_context = context + f"\n\nğŸ”— ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¹Ù„Ù…:\n{image_url}"
    
    final_prompt = prompt.format(context=full_context, landmark=landmark)
    return llm.invoke(final_prompt).content



  
 
def  rag_tool_func(query: str) -> str: 
    prompt = get_prompt_template_by_lang(detect_language(query)) 
    landmark = extract_landmark_name_from_text(query) 

    sourse = "Source of information from the knowledge base"
    qa_chain = RetrievalQA.from_chain_type( 
        llm=llm,
        retriever=retriever,
        chain_type="stuff",  # ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ù…Ø¹ ÙƒÙ„ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚prompt
        chain_type_kwargs={"prompt":  prompt },
        return_source_documents=True
    )
 
    try:
        rag_result = qa_chain({"query": query})
        answer = rag_result.get("result", "")
        
        if not answer.strip() or "Ù„Ø§ ØªÙˆØ¬Ø¯" in answer or "doesn't include" in answer  or "Ø¹Ø°Ø±Ù‹Ø§" in answer or len(answer) < 30:
            # fallback to Wikipedia
            print("ğŸ” Falling back to Wikipedia...")
            sourse = "Source of information from Wikipedia"

            Wiki_result =   text_tool_func(query) 

            return  {
            'answer': Wiki_result, 
            "lang": detect_language(query)  ,
            'sourse': sourse , 
    } 
            
         
        return   {
            'answer': answer, 
            "lang": detect_language(query)  ,
            'sourse': sourse , 
    } 
    
        
    except Exception as e:
        return f"âŒ Error occurred: {e}" , "ar" , "error"
    
 
def recognize_image(image_path: str) -> str:
    image = Image.open(image_path).convert("RGB")
    inputs = clip_processor(images=image, return_tensors="pt").to(device)
    with torch.no_grad():
        img_emb = clip_model.get_image_features(**inputs).cpu().numpy().astype('float32')
    _, indices = index.search(img_emb, k=1)
    idx = indices[0][0]
    return labels[idx] if idx < len(labels) else "Unknown Landmark"


def image_tool_func(image_path: str) -> str:
    landmark = recognize_image(image_path)
     
    if landmark == "Unknown Landmark":
        return "âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„Ù… ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©."
    
    return rag_tool_func(landmark) 
 




def audio_tool_func(audio_path: str , lang="en") -> str:
    r = sr.Recognizer()

    with sr.AudioFile(audio_path) as source:
        audio = r.record(source)

    # ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…
    text = r.recognize_google(audio ,  language= lang )
    landmark = extract_landmark_name_from_text(text) 
    return rag_tool_func(landmark) 
 

text_tool = Tool(
    name="RAGTourGuide",
    func=rag_tool_func,
    description="ÙŠØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„Ù… Ù…Ù† Ø§Ù„Ù†Øµ ÙˆÙŠØ±Ø¬Ø¹ ÙˆØµÙÙ‹Ø§ Ø³ÙŠØ§Ø­ÙŠÙ‹Ø§ ÙƒØ§Ù…Ù„Ø§Ù‹.",
    return_direct=True
)

image_tool = Tool(
    name="ImageTourGuide",
    func=image_tool_func,
    description="ÙŠØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„Ù… Ù…Ù† ØµÙˆØ±Ø© ÙˆÙŠØ±Ø¬Ø¹ ÙˆØµÙÙ‹Ø§ Ø³ÙŠØ§Ø­ÙŠÙ‹Ø§ ÙƒØ§Ù…Ù„Ø§Ù‹.",
    return_direct=True
)


audio_tool = Tool(
    name="AudioTourGuide",
    func=audio_tool_func,
    description="ÙŠØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„Ù… Ù…Ù† Ø§Ù„ØµÙˆØª ÙˆÙŠØ±Ø¬Ø¹ ÙˆØµÙÙ‹Ø§ Ø³ÙŠØ§Ø­ÙŠÙ‹Ø§ ÙƒØ§Ù…Ù„Ø§Ù‹.",
    return_direct=True
)


agent = initialize_agent(
    tools=[text_tool, image_tool, audio_tool],
    llm=llm,
    agent=AgentType.OPENAI_FUNCTIONS,
    verbose=True
)


def  multiple_values(result ):
      
    return isinstance(result, (tuple, list, dict)) 


# Start Here =)
def runSmartAgent( user_input ):

    resulte = agent.run( user_input )
     
    if multiple_values (resulte):
        answer = resulte["answer"].replace( "```html", '').replace( "```", '') 
        lang = resulte["lang"]
        sourse = resulte["sourse"]
        
        return answer , lang , sourse
   
    else:
        answer = resulte
        lang ="en"  
        sourse ="Source of information from the knowledge base"
        return answer , lang , sourse
        
     
    
  

    
